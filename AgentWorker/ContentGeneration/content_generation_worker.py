"""
å†…å®¹ç”ŸæˆAgentWorker

ä¸“é—¨ç”¨äºæ–‡ç« ã€åšå®¢ã€è¥é”€æ–‡æ¡ˆç­‰å†…å®¹ç”Ÿæˆçš„Agentå·¥ä½œæµ
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT / "src"))

from core.output_control import OutputController
from core.config.llm_manager import LLMManager


class ContentGenerationWorker:
    """å†…å®¹ç”Ÿæˆå·¥ä½œå™¨"""
    
    def __init__(self, llm_model: str = "gpt-4o-mini"):
        """
        åˆå§‹åŒ–å†…å®¹ç”Ÿæˆå·¥ä½œå™¨
        
        Args:
            llm_model: ä½¿ç”¨çš„LLMæ¨¡å‹
        """
        self.llm_model = llm_model
        self.llm_manager = LLMManager()
        
        # ä»æœ¬åœ°é…ç½®åŠ è½½è¾“å‡ºæ§åˆ¶å™¨
        config_path = Path(__file__).parent / "configs" / "output_control.yaml"
        self.output_controller = OutputController.from_config_file(
            str(config_path),
            llm_client=self.llm_manager.get_client()
        )
        
        print(f"âœ… å†…å®¹ç”Ÿæˆå·¥ä½œå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {llm_model}")
    
    async def generate_article(self, topic: str, target_audience: str = "é€šç”¨è¯»è€…", length: str = "ä¸­ç­‰") -> Dict[str, Any]:
        """
        ç”Ÿæˆæ–‡ç« 
        
        Args:
            topic: æ–‡ç« ä¸»é¢˜
            target_audience: ç›®æ ‡è¯»è€…
            length: æ–‡ç« é•¿åº¦ (çŸ­/ä¸­ç­‰/é•¿)
            
        Returns:
            åŒ…å«æ–‡ç« å†…å®¹å’Œè´¨é‡ä¿¡æ¯çš„å­—å…¸
        """
        # æ„å»ºprompt
        length_guide = {
            "çŸ­": "500-800å­—",
            "ä¸­ç­‰": "1000-1500å­—", 
            "é•¿": "2000-3000å­—"
        }
        
        prompt = f"""è¯·ä¸ºä¸»é¢˜"{topic}"æ’°å†™ä¸€ç¯‡é¢å‘{target_audience}çš„æ–‡ç« ï¼Œé•¿åº¦çº¦{length_guide.get(length, '1000-1500å­—')}ã€‚

è¦æ±‚ï¼š
1. åŒ…å«å¸å¼•äººçš„æ ‡é¢˜
2. ç»“æ„å®Œæ•´ï¼šå¼•è¨€ã€ä¸»ä½“å†…å®¹ã€ç»“è®º
3. è¯­è¨€æµç•…ï¼Œé€»è¾‘æ¸…æ™°
4. æä¾›å®ç”¨ä»·å€¼
5. ä½¿ç”¨Markdownæ ¼å¼

è¯·ç¡®ä¿å†…å®¹åŸåˆ›ã€å‡†ç¡®ï¼Œé¿å…æ•æ„Ÿè¯é¢˜ã€‚"""

        # è°ƒç”¨LLMç”Ÿæˆåˆå§‹å†…å®¹
        llm_client = self.llm_manager.get_client()
        initial_output = await llm_client.generate(prompt, model=self.llm_model)
        
        # åº”ç”¨è¾“å‡ºæ§åˆ¶
        control_result = await self.output_controller.control_output(
            original_prompt=prompt,
            agent_output=initial_output,
            output_type="article"
        )
        
        return {
            "success": control_result.success,
            "content": control_result.final_output,
            "original_content": control_result.original_output,
            "quality_score": self._calculate_quality_score(control_result),
            "improvements_made": len([r for r in control_result.processing_results if r.changes_made]),
            "re_prompt_attempts": control_result.re_prompt_attempts,
            "processing_time": control_result.processing_time,
            "topic": topic,
            "target_audience": target_audience,
            "length": length
        }
    
    async def generate_blog_post(self, topic: str, style: str = "conversational") -> Dict[str, Any]:
        """
        ç”Ÿæˆåšå®¢æ–‡ç« 
        
        Args:
            topic: åšå®¢ä¸»é¢˜
            style: å†™ä½œé£æ ¼ (conversational/professional/casual)
            
        Returns:
            åŒ…å«åšå®¢å†…å®¹å’Œè´¨é‡ä¿¡æ¯çš„å­—å…¸
        """
        style_guides = {
            "conversational": "é‡‡ç”¨å¯¹è¯å¼è¯­è°ƒï¼Œäº²åˆ‡è‡ªç„¶ï¼Œå¦‚åŒä¸æœ‹å‹äº¤è°ˆ",
            "professional": "ä½¿ç”¨ä¸“ä¸šã€æ­£å¼çš„è¯­è¨€ï¼Œæ³¨é‡æƒå¨æ€§",
            "casual": "è½»æ¾éšæ„çš„è¯­è°ƒï¼Œå¹½é»˜é£è¶£"
        }
        
        prompt = f"""è¯·æ’°å†™ä¸€ç¯‡å…³äº"{topic}"çš„åšå®¢æ–‡ç« ã€‚

å†™ä½œé£æ ¼ï¼š{style_guides.get(style, 'å¯¹è¯å¼è¯­è°ƒ')}

è¦æ±‚ï¼š
1. åŒ…å«ä¸ªäººè§‚ç‚¹å’Œç»éªŒåˆ†äº«
2. ç»“æ„ï¼šå¼•å…¥è¯é¢˜ã€å±•å¼€è®¨è®ºã€ä¸ªäººæ€è€ƒã€ç»“è®º
3. é•¿åº¦æ§åˆ¶åœ¨800-1500å­—
4. ä½¿ç”¨Markdownæ ¼å¼
5. å¯ä»¥åŒ…å«ä¸€äº›ä¸ªäººåŒ–çš„å…ƒç´ 

è¯·ç¡®ä¿å†…å®¹æœ‰è¶£ã€æœ‰ä»·å€¼ï¼Œèƒ½å¤Ÿå¼•èµ·è¯»è€…å…±é¸£ã€‚"""

        # è°ƒç”¨LLMç”Ÿæˆå†…å®¹
        llm_client = self.llm_manager.get_client()
        initial_output = await llm_client.generate(prompt, model=self.llm_model)
        
        # åº”ç”¨è¾“å‡ºæ§åˆ¶
        control_result = await self.output_controller.control_output(
            original_prompt=prompt,
            agent_output=initial_output,
            output_type="blog"
        )
        
        return {
            "success": control_result.success,
            "content": control_result.final_output,
            "quality_score": self._calculate_quality_score(control_result),
            "style": style,
            "topic": topic,
            "processing_info": self._get_processing_info(control_result)
        }
    
    async def generate_marketing_copy(self, product: str, target_market: str, copy_type: str = "é”€å”®é¡µé¢") -> Dict[str, Any]:
        """
        ç”Ÿæˆè¥é”€æ–‡æ¡ˆ
        
        Args:
            product: äº§å“åç§°
            target_market: ç›®æ ‡å¸‚åœº
            copy_type: æ–‡æ¡ˆç±»å‹ (é”€å”®é¡µé¢/å¹¿å‘Šæ–‡æ¡ˆ/é‚®ä»¶è¥é”€)
            
        Returns:
            åŒ…å«è¥é”€æ–‡æ¡ˆå’Œæ•ˆæœè¯„ä¼°çš„å­—å…¸
        """
        copy_templates = {
            "é”€å”®é¡µé¢": "åŒ…å«ä»·å€¼ä¸»å¼ ã€ç‰¹è‰²åŠŸèƒ½ã€å®¢æˆ·è¯è¨€ã€è¡ŒåŠ¨å¬å”¤çš„å®Œæ•´é”€å”®é¡µé¢",
            "å¹¿å‘Šæ–‡æ¡ˆ": "ç®€æ´æœ‰åŠ›çš„å¹¿å‘Šæ–‡æ¡ˆï¼Œçªå‡ºæ ¸å¿ƒå–ç‚¹",
            "é‚®ä»¶è¥é”€": "ä¸ªæ€§åŒ–çš„é‚®ä»¶è¥é”€å†…å®¹ï¼ŒåŒ…å«ä¸»é¢˜è¡Œå’Œæ­£æ–‡"
        }
        
        prompt = f"""è¯·ä¸ºäº§å“"{product}"åˆ›ä½œ{copy_type}ï¼Œç›®æ ‡å¸‚åœºæ˜¯{target_market}ã€‚

æ–‡æ¡ˆç±»å‹ï¼š{copy_templates.get(copy_type, 'é”€å”®æ–‡æ¡ˆ')}

è¦æ±‚ï¼š
1. çªå‡ºäº§å“çš„æ ¸å¿ƒä»·å€¼å’Œç‹¬ç‰¹å–ç‚¹
2. é’ˆå¯¹ç›®æ ‡å¸‚åœºçš„ç—›ç‚¹å’Œéœ€æ±‚
3. åŒ…å«å¼ºæœ‰åŠ›çš„è¡ŒåŠ¨å¬å”¤
4. è¯­è¨€æœ‰è¯´æœåŠ›ï¼Œèƒ½æ¿€å‘è´­ä¹°æ¬²æœ›
5. ä½¿ç”¨Markdownæ ¼å¼

è¯·ç¡®ä¿æ–‡æ¡ˆçœŸå®å¯ä¿¡ï¼Œé¿å…å¤¸å¤§å®£ä¼ ã€‚"""

        # è°ƒç”¨LLMç”Ÿæˆå†…å®¹
        llm_client = self.llm_manager.get_client()
        initial_output = await llm_client.generate(prompt, model=self.llm_model)
        
        # åº”ç”¨è¾“å‡ºæ§åˆ¶
        control_result = await self.output_controller.control_output(
            original_prompt=prompt,
            agent_output=initial_output,
            output_type="marketing"
        )
        
        return {
            "success": control_result.success,
            "content": control_result.final_output,
            "product": product,
            "target_market": target_market,
            "copy_type": copy_type,
            "quality_score": self._calculate_quality_score(control_result),
            "processing_info": self._get_processing_info(control_result)
        }
    
    def _calculate_quality_score(self, control_result) -> float:
        """è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°"""
        if not control_result.success:
            return 0.0
        
        # åŸºç¡€åˆ†æ•°
        base_score = 7.0
        
        # å¦‚æœæ²¡æœ‰çº¦æŸè¿åï¼ŒåŠ åˆ†
        if not any(r.status.value == 'failed' for r in control_result.constraint_violations):
            base_score += 1.0
        
        # å¦‚æœéªŒè¯å…¨éƒ¨é€šè¿‡ï¼ŒåŠ åˆ†
        if all(r.status.value == 'passed' for r in control_result.validation_results):
            base_score += 1.0
        
        # å¦‚æœæœ‰å¤„ç†æ”¹è¿›ï¼ŒåŠ åˆ†
        if any(r.changes_made for r in control_result.processing_results):
            base_score += 0.5
        
        # å¦‚æœéœ€è¦re-promptï¼Œå‡åˆ†
        if control_result.re_prompt_attempts > 0:
            base_score -= 0.5 * control_result.re_prompt_attempts
        
        return max(0.0, min(10.0, base_score))
    
    def _get_processing_info(self, control_result) -> Dict[str, Any]:
        """è·å–å¤„ç†ä¿¡æ¯æ‘˜è¦"""
        return {
            "constraint_violations": len([r for r in control_result.constraint_violations if r.status.value == 'failed']),
            "validation_results": len([r for r in control_result.validation_results if r.status.value == 'passed']),
            "processing_results": len([r for r in control_result.processing_results if r.changes_made]),
            "re_prompt_attempts": control_result.re_prompt_attempts,
            "processing_time": control_result.processing_time
        }
    
    async def batch_generate(self, tasks: list) -> Dict[str, Any]:
        """æ‰¹é‡ç”Ÿæˆå†…å®¹"""
        results = []
        
        for task in tasks:
            task_type = task.get('type', 'article')
            
            if task_type == 'article':
                result = await self.generate_article(
                    topic=task['topic'],
                    target_audience=task.get('target_audience', 'é€šç”¨è¯»è€…'),
                    length=task.get('length', 'ä¸­ç­‰')
                )
            elif task_type == 'blog':
                result = await self.generate_blog_post(
                    topic=task['topic'],
                    style=task.get('style', 'conversational')
                )
            elif task_type == 'marketing':
                result = await self.generate_marketing_copy(
                    product=task['product'],
                    target_market=task['target_market'],
                    copy_type=task.get('copy_type', 'é”€å”®é¡µé¢')
                )
            else:
                result = {"success": False, "error": f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}"}
            
            results.append(result)
        
        return {
            "total_tasks": len(tasks),
            "successful_tasks": sum(1 for r in results if r.get('success', False)),
            "average_quality": sum(r.get('quality_score', 0) for r in results) / len(results) if results else 0,
            "results": results
        }


async def demo_content_generation():
    """å†…å®¹ç”Ÿæˆæ¼”ç¤º"""
    print("ğŸ¨ å†…å®¹ç”ŸæˆAgentWorkeræ¼”ç¤º")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–å·¥ä½œå™¨
        worker = ContentGenerationWorker()
        
        # æ¼”ç¤º1ï¼šç”Ÿæˆæ–‡ç« 
        print("\nğŸ“ æ¼”ç¤º1ï¼šç”Ÿæˆæ–‡ç« ")
        article_result = await worker.generate_article(
            topic="äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨å‰æ™¯",
            target_audience="æ•™è‚²å·¥ä½œè€…",
            length="ä¸­ç­‰"
        )
        
        print(f"âœ… æ–‡ç« ç”Ÿæˆ{'æˆåŠŸ' if article_result['success'] else 'å¤±è´¥'}")
        print(f"ğŸ† è´¨é‡è¯„åˆ†: {article_result['quality_score']:.1f}/10")
        print(f"ğŸ”„ æ”¹è¿›æ¬¡æ•°: {article_result['improvements_made']}")
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {article_result['processing_time']:.2f}s")
        print(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(article_result['content'])} å­—ç¬¦")
        
        # æ¼”ç¤º2ï¼šç”Ÿæˆåšå®¢
        print("\nğŸ“ æ¼”ç¤º2ï¼šç”Ÿæˆåšå®¢æ–‡ç« ")
        blog_result = await worker.generate_blog_post(
            topic="è¿œç¨‹å·¥ä½œçš„ä¼˜ç¼ºç‚¹åŠä¸ªäººä½“éªŒ",
            style="conversational"
        )
        
        print(f"âœ… åšå®¢ç”Ÿæˆ{'æˆåŠŸ' if blog_result['success'] else 'å¤±è´¥'}")
        print(f"ğŸ† è´¨é‡è¯„åˆ†: {blog_result['quality_score']:.1f}/10")
        
        # æ¼”ç¤º3ï¼šç”Ÿæˆè¥é”€æ–‡æ¡ˆ
        print("\nğŸ“ æ¼”ç¤º3ï¼šç”Ÿæˆè¥é”€æ–‡æ¡ˆ")
        marketing_result = await worker.generate_marketing_copy(
            product="æ™ºèƒ½è¯­è¨€å­¦ä¹ APP",
            target_market="å¹´è½»ç™½é¢†",
            copy_type="é”€å”®é¡µé¢"
        )
        
        print(f"âœ… è¥é”€æ–‡æ¡ˆç”Ÿæˆ{'æˆåŠŸ' if marketing_result['success'] else 'å¤±è´¥'}")
        print(f"ğŸ† è´¨é‡è¯„åˆ†: {marketing_result['quality_score']:.1f}/10")
        
        # æ¼”ç¤º4ï¼šæ‰¹é‡ç”Ÿæˆ
        print("\nğŸ“ æ¼”ç¤º4ï¼šæ‰¹é‡ç”Ÿæˆ")
        batch_tasks = [
            {"type": "article", "topic": "å¯æŒç»­å‘å±•çš„é‡è¦æ€§", "length": "çŸ­"},
            {"type": "blog", "topic": "å¥åº·ç”Ÿæ´»å°è´´å£«", "style": "casual"},
            {"type": "marketing", "product": "æœ‰æœºå’–å•¡", "target_market": "å¥åº·æ„è¯†æ¶ˆè´¹è€…"}
        ]
        
        batch_result = await worker.batch_generate(batch_tasks)
        print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ: {batch_result['successful_tasks']}/{batch_result['total_tasks']}")
        print(f"ğŸ† å¹³å‡è´¨é‡: {batch_result['average_quality']:.1f}/10")
        
        print("\nğŸ‰ å†…å®¹ç”Ÿæˆæ¼”ç¤ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(demo_content_generation())