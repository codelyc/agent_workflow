# æ•…éšœæ’é™¤æŒ‡å—

æœ¬æŒ‡å—æä¾›äº†AI Agents Workflowæ¡†æ¶å¸¸è§é—®é¢˜çš„è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿè¯†åˆ«å’Œä¿®å¤é—®é¢˜ã€‚

## ç›®å½•

- [å¿«é€Ÿè¯Šæ–­](#å¿«é€Ÿè¯Šæ–­)
- [å®‰è£…å’Œé…ç½®é—®é¢˜](#å®‰è£…å’Œé…ç½®é—®é¢˜)
- [è¿è¡Œæ—¶é”™è¯¯](#è¿è¡Œæ—¶é”™è¯¯)
- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
- [APIå’Œç½‘ç»œé—®é¢˜](#apiå’Œç½‘ç»œé—®é¢˜)
- [æ•°æ®åº“é—®é¢˜](#æ•°æ®åº“é—®é¢˜)
- [å†…å­˜å’Œèµ„æºé—®é¢˜](#å†…å­˜å’Œèµ„æºé—®é¢˜)
- [æ—¥å¿—åˆ†æ](#æ—¥å¿—åˆ†æ)
- [è°ƒè¯•å·¥å…·](#è°ƒè¯•å·¥å…·)
- [å¸¸è§é”™è¯¯ä»£ç ](#å¸¸è§é”™è¯¯ä»£ç )

## å¿«é€Ÿè¯Šæ–­

### ç³»ç»Ÿå¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥Pythonç¯å¢ƒ
python --version
pip list | grep -E "(aiohttp|pydantic|openai)"

# æ£€æŸ¥é¡¹ç›®ç»“æ„
ls -la src/
ls -la AgentWorker/

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat configs/default_config.yaml

# æµ‹è¯•åŸºæœ¬å¯¼å…¥
python -c "from src.core.config.config_manager import ConfigManager; print('å¯¼å…¥æˆåŠŸ')"
```

### å¿«é€Ÿæµ‹è¯•è„šæœ¬

```python
# scripts/quick_test.py
import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root))

async def quick_test():
    """å¿«é€Ÿæµ‹è¯•ç³»ç»Ÿç»„ä»¶"""
    print("ğŸ” å¼€å§‹å¿«é€Ÿè¯Šæ–­...")
    
    # æµ‹è¯•1: å¯¼å…¥æ ¸å¿ƒæ¨¡å—
    try:
        from src.core.config.config_manager import ConfigManager
        from src.core.output_control import OutputController
        print("âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•2: é…ç½®ç®¡ç†å™¨
    try:
        config_manager = ConfigManager()
        config = config_manager.load_config("default_config.yaml")
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•3: è¾“å‡ºæ§åˆ¶å™¨
    try:
        output_controller = OutputController()
        await output_controller.display_message("æµ‹è¯•æ¶ˆæ¯", "info")
        print("âœ… è¾“å‡ºæ§åˆ¶å™¨å·¥ä½œæ­£å¸¸")
    except Exception as e:
        print(f"âŒ è¾“å‡ºæ§åˆ¶å™¨å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•4: ç¯å¢ƒå˜é‡
    api_key = os.getenv('OPENAI_API_KEY')
    if api_key:
        print("âœ… APIå¯†é’¥å·²é…ç½®")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
    
    print("ğŸ‰ å¿«é€Ÿè¯Šæ–­å®Œæˆ")
    return True

if __name__ == "__main__":
    success = asyncio.run(quick_test())
    sys.exit(0 if success else 1)
```

## å®‰è£…å’Œé…ç½®é—®é¢˜

### é—®é¢˜1: æ¨¡å—å¯¼å…¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯ï¼š**
```
ModuleNotFoundError: No module named 'src.core.config'
```

**åŸå› åˆ†æï¼š**
- Pythonè·¯å¾„é…ç½®ä¸æ­£ç¡®
- é¡¹ç›®ç»“æ„é—®é¢˜
- è™šæ‹Ÿç¯å¢ƒæœªæ¿€æ´»

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ–¹æ¡ˆ1: æ£€æŸ¥å¹¶ä¿®å¤Pythonè·¯å¾„
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src:$(pwd)"

# æ–¹æ¡ˆ2: å®‰è£…ä¸ºå¯ç¼–è¾‘åŒ…
pip install -e .

# æ–¹æ¡ˆ3: åˆ›å»º.pthæ–‡ä»¶
echo "$(pwd)/src" > $(python -c "import site; print(site.getsitepackages()[0])")/agent_workflow.pth

# æ–¹æ¡ˆ4: æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
which python
pip list
```

**IDEé…ç½®ä¿®å¤ï¼š**

```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.analysis.extraPaths": ["./src", "./AgentWorker"],
    "python.analysis.autoSearchPaths": true,
    "python.analysis.autoImportCompletions": true
}
```

### é—®é¢˜2: ä¾èµ–ç‰ˆæœ¬å†²çª

**é”™è¯¯ä¿¡æ¯ï¼š**
```
ERROR: pip's dependency resolver does not currently consider all the packages that are installed
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ¸…ç†ç¯å¢ƒ
pip freeze > requirements_backup.txt
pip uninstall -r requirements_backup.txt -y

# é‡æ–°å®‰è£…
pip install --upgrade pip
pip install -r requirements.txt

# æˆ–ä½¿ç”¨uv (æ¨è)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
```

### é—®é¢˜3: é…ç½®æ–‡ä»¶æ‰¾ä¸åˆ°

**é”™è¯¯ä¿¡æ¯ï¼š**
```
FileNotFoundError: [Errno 2] No such file or directory: 'configs/default_config.yaml'
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# æ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„
import os
from pathlib import Path

# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent
config_path = project_root / "configs" / "default_config.yaml"

print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}")
print(f"æ–‡ä»¶å­˜åœ¨: {config_path.exists()}")

# å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
if not config_path.exists():
    config_path.parent.mkdir(parents=True, exist_ok=True)
    with open(config_path, 'w') as f:
        f.write('''
# é»˜è®¤é…ç½®
version: "1.0"

# ä»£ç†é…ç½®
agents:
  code_assistant:
    enabled: true
    model: "gpt-3.5-turbo"
    max_tokens: 2000

# LLMé…ç½®
llm:
  providers:
    openai:
      api_key: "${OPENAI_API_KEY}"
      base_url: "https://api.openai.com/v1"

# è¾“å‡ºé…ç½®
output:
  console:
    enabled: true
    level: "info"
  file:
    enabled: false
        ''')
```

## è¿è¡Œæ—¶é”™è¯¯

### é—®é¢˜1: å¼‚æ­¥å‡½æ•°è°ƒç”¨é”™è¯¯

**é”™è¯¯ä¿¡æ¯ï¼š**
```
RuntimeError: asyncio.run() cannot be called from a running event loop
```

**åŸå› åˆ†æï¼š**
- åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸­è°ƒç”¨`asyncio.run()`
- Jupyter notebookç¯å¢ƒé—®é¢˜

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# é”™è¯¯çš„è°ƒç”¨æ–¹å¼
# asyncio.run(some_async_function())

# æ­£ç¡®çš„è°ƒç”¨æ–¹å¼
import asyncio

# æ–¹æ¡ˆ1: æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯
try:
    loop = asyncio.get_running_loop()
    # å¦‚æœæœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œç›´æ¥await
    result = await some_async_function()
except RuntimeError:
    # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œä½¿ç”¨asyncio.run
    result = asyncio.run(some_async_function())

# æ–¹æ¡ˆ2: ä½¿ç”¨nest_asyncio (é€‚ç”¨äºJupyter)
import nest_asyncio
nest_asyncio.apply()
result = asyncio.run(some_async_function())

# æ–¹æ¡ˆ3: åˆ›å»ºä»»åŠ¡
loop = asyncio.get_event_loop()
task = loop.create_task(some_async_function())
result = await task
```

### é—®é¢˜2: ä»»åŠ¡è¶…æ—¶

**é”™è¯¯ä¿¡æ¯ï¼š**
```
asyncio.TimeoutError: Task timed out after 30 seconds
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# å¢åŠ è¶…æ—¶æ—¶é—´
import asyncio

async def process_with_timeout(task, timeout=60):
    try:
        result = await asyncio.wait_for(task, timeout=timeout)
        return result
    except asyncio.TimeoutError:
        print(f"ä»»åŠ¡è¶…æ—¶ ({timeout}ç§’)")
        # å®ç°é‡è¯•é€»è¾‘
        return await retry_task(task)

async def retry_task(task, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await asyncio.wait_for(task, timeout=120)
        except asyncio.TimeoutError:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### é—®é¢˜3: å†…å­˜æ³„æ¼

**ç—‡çŠ¶ï¼š**
- å†…å­˜ä½¿ç”¨æŒç»­å¢é•¿
- åº”ç”¨å˜æ…¢æˆ–å´©æºƒ

**è¯Šæ–­å·¥å…·ï¼š**

```python
# memory_profiler.py
import psutil
import gc
import tracemalloc
from typing import Dict, Any

class MemoryProfiler:
    def __init__(self):
        self.start_memory = None
        tracemalloc.start()
    
    def start_profiling(self):
        """å¼€å§‹å†…å­˜åˆ†æ"""
        self.start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        print(f"å¼€å§‹å†…å­˜ä½¿ç”¨: {self.start_memory:.2f} MB")
    
    def check_memory(self, label: str = ""):
        """æ£€æŸ¥å½“å‰å†…å­˜ä½¿ç”¨"""
        current_memory = psutil.Process().memory_info().rss / 1024 / 1024
        if self.start_memory:
            diff = current_memory - self.start_memory
            print(f"{label} å†…å­˜ä½¿ç”¨: {current_memory:.2f} MB (+{diff:.2f} MB)")
        else:
            print(f"{label} å†…å­˜ä½¿ç”¨: {current_memory:.2f} MB")
    
    def get_top_memory_objects(self, limit=10):
        """è·å–å ç”¨å†…å­˜æœ€å¤šçš„å¯¹è±¡"""
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')
        
        print(f"Top {limit} memory consumers:")
        for index, stat in enumerate(top_stats[:limit], 1):
            print(f"{index}. {stat}")
    
    def force_gc(self):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        before = psutil.Process().memory_info().rss / 1024 / 1024
        collected = gc.collect()
        after = psutil.Process().memory_info().rss / 1024 / 1024
        print(f"åƒåœ¾å›æ”¶: å›æ”¶äº† {collected} ä¸ªå¯¹è±¡, é‡Šæ”¾äº† {before-after:.2f} MB")

# ä½¿ç”¨ç¤ºä¾‹
profiler = MemoryProfiler()
profiler.start_profiling()

# åœ¨å…³é”®ç‚¹æ£€æŸ¥å†…å­˜
profiler.check_memory("å¤„ç†ä»»åŠ¡å")
profiler.get_top_memory_objects()
profiler.force_gc()
```

## æ€§èƒ½é—®é¢˜

### é—®é¢˜1: å“åº”æ—¶é—´è¿‡é•¿

**è¯Šæ–­å·¥å…·ï¼š**

```python
# performance_monitor.py
import time
import asyncio
from functools import wraps
from typing import Callable, Any

def performance_monitor(func: Callable) -> Callable:
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    async def async_wrapper(*args, **kwargs) -> Any:
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            end_time = time.time()
            duration = end_time - start_time
            print(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {duration:.2f}ç§’")
            
            # å¦‚æœæ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œè®°å½•è­¦å‘Š
            if duration > 10:
                print(f"âš ï¸ {func.__name__} æ‰§è¡Œæ—¶é—´è¿‡é•¿: {duration:.2f}ç§’")
    
    @wraps(func)
    def sync_wrapper(*args, **kwargs) -> Any:
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            end_time = time.time()
            duration = end_time - start_time
            print(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {duration:.2f}ç§’")
    
    return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

# ä½¿ç”¨ç¤ºä¾‹
@performance_monitor
async def slow_function():
    await asyncio.sleep(5)
    return "å®Œæˆ"
```

**ä¼˜åŒ–ç­–ç•¥ï¼š**

```python
# å¹¶å‘å¤„ç†
async def process_tasks_concurrently(tasks, max_concurrent=5):
    """å¹¶å‘å¤„ç†ä»»åŠ¡"""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_with_semaphore(task):
        async with semaphore:
            return await process_single_task(task)
    
    results = await asyncio.gather(*[
        process_with_semaphore(task) for task in tasks
    ])
    return results

# ç¼“å­˜ç»“æœ
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_computation(input_data):
    """ç¼“å­˜è®¡ç®—ç»“æœ"""
    # è€—æ—¶è®¡ç®—
    return result

# æ‰¹å¤„ç†
async def batch_process(items, batch_size=10):
    """æ‰¹é‡å¤„ç†"""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        await process_batch(batch)
        await asyncio.sleep(0.1)  # é¿å…è¿‡è½½
```

### é—®é¢˜2: CPUä½¿ç”¨ç‡è¿‡é«˜

**è¯Šæ–­è„šæœ¬ï¼š**

```python
# cpu_monitor.py
import psutil
import time
import threading
from collections import deque

class CPUMonitor:
    def __init__(self, window_size=60):
        self.cpu_history = deque(maxlen=window_size)
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹CPUç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢CPUç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            cpu_percent = psutil.cpu_percent(interval=1)
            self.cpu_history.append(cpu_percent)
            
            if cpu_percent > 80:
                print(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent}%")
                self._analyze_high_cpu()
    
    def _analyze_high_cpu(self):
        """åˆ†æé«˜CPUä½¿ç”¨ç‡"""
        # è·å–è¿›ç¨‹ä¿¡æ¯
        process = psutil.Process()
        threads = process.threads()
        
        print(f"å½“å‰è¿›ç¨‹çº¿ç¨‹æ•°: {len(threads)}")
        print(f"å†…å­˜ä½¿ç”¨: {process.memory_info().rss / 1024 / 1024:.2f} MB")
        
        # æ£€æŸ¥å­è¿›ç¨‹
        children = process.children(recursive=True)
        if children:
            print(f"å­è¿›ç¨‹æ•°: {len(children)}")
    
    def get_average_cpu(self):
        """è·å–å¹³å‡CPUä½¿ç”¨ç‡"""
        if self.cpu_history:
            return sum(self.cpu_history) / len(self.cpu_history)
        return 0

# ä½¿ç”¨ç¤ºä¾‹
monitor = CPUMonitor()
monitor.start_monitoring()

# è¿è¡Œä½ çš„ä»£ç 
# ...

print(f"å¹³å‡CPUä½¿ç”¨ç‡: {monitor.get_average_cpu():.2f}%")
monitor.stop_monitoring()
```

## APIå’Œç½‘ç»œé—®é¢˜

### é—®é¢˜1: APIè°ƒç”¨å¤±è´¥

**é”™è¯¯ä¿¡æ¯ï¼š**
```
openai.error.RateLimitError: Rate limit exceeded
openai.error.AuthenticationError: Invalid API key
openai.error.APIConnectionError: Connection error
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# api_client_with_retry.py
import asyncio
import aiohttp
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from typing import Dict, Any, Optional

class RobustAPIClient:
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.session: Optional[aiohttp.ClientSession] = None
    
    async def get_session(self) -> aiohttp.ClientSession:
        """è·å–HTTPä¼šè¯"""
        if self.session is None or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=60, connect=10)
            connector = aiohttp.TCPConnector(
                limit=10,
                ttl_dns_cache=300,
                use_dns_cache=True
            )
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector,
                headers={"Authorization": f"Bearer {self.api_key}"}
            )
        return self.session
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError))
    )
    async def make_request(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """å‘èµ·APIè¯·æ±‚"""
        session = await self.get_session()
        url = f"{self.base_url}/{endpoint}"
        
        try:
            async with session.post(url, json=data) as response:
                if response.status == 429:  # Rate limit
                    retry_after = int(response.headers.get('Retry-After', 60))
                    print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {retry_after} ç§’")
                    await asyncio.sleep(retry_after)
                    raise aiohttp.ClientError("Rate limit exceeded")
                
                if response.status == 401:  # Authentication error
                    raise ValueError("APIå¯†é’¥æ— æ•ˆ")
                
                response.raise_for_status()
                return await response.json()
        
        except aiohttp.ClientError as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {e}")
            raise
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session and not self.session.closed:
            await self.session.close()

# ç½‘ç»œè¿æ¥æµ‹è¯•
async def test_network_connectivity():
    """æµ‹è¯•ç½‘ç»œè¿æ¥"""
    test_urls = [
        "https://api.openai.com",
        "https://api.anthropic.com",
        "https://www.google.com"
    ]
    
    async with aiohttp.ClientSession() as session:
        for url in test_urls:
            try:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    print(f"âœ… {url}: {response.status}")
            except Exception as e:
                print(f"âŒ {url}: {e}")
```

### é—®é¢˜2: ä»£ç†å’Œé˜²ç«å¢™é—®é¢˜

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# proxy_config.py
import os
import aiohttp

def setup_proxy_session():
    """é…ç½®ä»£ç†ä¼šè¯"""
    proxy_url = os.getenv('HTTP_PROXY') or os.getenv('HTTPS_PROXY')
    
    if proxy_url:
        print(f"ä½¿ç”¨ä»£ç†: {proxy_url}")
        connector = aiohttp.TCPConnector(
            limit=10,
            verify_ssl=False  # å¦‚æœä»£ç†æœ‰SSLé—®é¢˜
        )
        return aiohttp.ClientSession(
            connector=connector,
            trust_env=True  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
        )
    else:
        return aiohttp.ClientSession()

# ç¯å¢ƒå˜é‡è®¾ç½®
# export HTTP_PROXY=http://proxy.company.com:8080
# export HTTPS_PROXY=http://proxy.company.com:8080
# export NO_PROXY=localhost,127.0.0.1,.local
```

## æ•°æ®åº“é—®é¢˜

### é—®é¢˜1: è¿æ¥æ± è€—å°½

**é”™è¯¯ä¿¡æ¯ï¼š**
```
sqlalchemy.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# database_config.py
from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.pool import QueuePool

def create_optimized_engine(database_url: str):
    """åˆ›å»ºä¼˜åŒ–çš„æ•°æ®åº“å¼•æ“"""
    return create_async_engine(
        database_url,
        # è¿æ¥æ± é…ç½®
        pool_size=20,          # è¿æ¥æ± å¤§å°
        max_overflow=30,       # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
        pool_timeout=30,       # è·å–è¿æ¥è¶…æ—¶æ—¶é—´
        pool_recycle=3600,     # è¿æ¥å›æ”¶æ—¶é—´
        pool_pre_ping=True,    # è¿æ¥å‰pingæµ‹è¯•
        
        # å…¶ä»–é…ç½®
        echo=False,            # ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
        future=True,
        
        # è¿æ¥å‚æ•°
        connect_args={
            "command_timeout": 60,
            "server_settings": {
                "application_name": "agent_workflow",
            }
        }
    )

# è¿æ¥ç®¡ç†å™¨
class DatabaseManager:
    def __init__(self, database_url: str):
        self.engine = create_optimized_engine(database_url)
        self.active_connections = 0
    
    async def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            self.active_connections += 1
            async with self.engine.begin() as conn:
                yield conn
        finally:
            self.active_connections -= 1
    
    async def check_pool_status(self):
        """æ£€æŸ¥è¿æ¥æ± çŠ¶æ€"""
        pool = self.engine.pool
        print(f"è¿æ¥æ± çŠ¶æ€:")
        print(f"  å¤§å°: {pool.size()}")
        print(f"  å·²æ£€å‡º: {pool.checkedout()}")
        print(f"  æº¢å‡º: {pool.overflow()}")
        print(f"  æ— æ•ˆ: {pool.invalidated()}")
```

### é—®é¢˜2: æ­»é”å’Œé•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢

**è¯Šæ–­å·¥å…·ï¼š**

```sql
-- PostgreSQLæ­»é”æ£€æµ‹
SELECT 
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS current_statement_in_blocking_process
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.DATABASE IS NOT DISTINCT FROM blocked_locks.DATABASE
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.GRANTED;

-- é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
SELECT 
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query,
    state
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes'
ORDER BY duration DESC;
```

**Pythonç›‘æ§è„šæœ¬ï¼š**

```python
# db_monitor.py
import asyncio
import asyncpg
from datetime import datetime, timedelta

class DatabaseMonitor:
    def __init__(self, database_url: str):
        self.database_url = database_url
    
    async def check_long_running_queries(self, threshold_minutes=5):
        """æ£€æŸ¥é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢"""
        conn = await asyncpg.connect(self.database_url)
        
        query = """
        SELECT 
            pid,
            now() - query_start AS duration,
            query,
            state
        FROM pg_stat_activity
        WHERE (now() - query_start) > interval '%s minutes'
        AND state != 'idle'
        ORDER BY duration DESC;
        """ % threshold_minutes
        
        try:
            rows = await conn.fetch(query)
            if rows:
                print(f"å‘ç° {len(rows)} ä¸ªé•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢:")
                for row in rows:
                    print(f"PID: {row['pid']}, æŒç»­æ—¶é—´: {row['duration']}, æŸ¥è¯¢: {row['query'][:100]}...")
            return rows
        finally:
            await conn.close()
    
    async def check_deadlocks(self):
        """æ£€æŸ¥æ­»é”"""
        conn = await asyncpg.connect(self.database_url)
        
        query = """
        SELECT 
            blocked_locks.pid AS blocked_pid,
            blocking_locks.pid AS blocking_pid,
            blocked_activity.query AS blocked_query,
            blocking_activity.query AS blocking_query
        FROM pg_catalog.pg_locks blocked_locks
        JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
        JOIN pg_catalog.pg_locks blocking_locks ON (
            blocking_locks.locktype = blocked_locks.locktype
            AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
            AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
            AND blocking_locks.pid != blocked_locks.pid
        )
        JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
        WHERE NOT blocked_locks.granted;
        """
        
        try:
            rows = await conn.fetch(query)
            if rows:
                print(f"å‘ç° {len(rows)} ä¸ªæ­»é”:")
                for row in rows:
                    print(f"è¢«é˜»å¡PID: {row['blocked_pid']}, é˜»å¡PID: {row['blocking_pid']}")
            return rows
        finally:
            await conn.close()
```

## å†…å­˜å’Œèµ„æºé—®é¢˜

### å†…å­˜æ³„æ¼æ£€æµ‹

```python
# memory_leak_detector.py
import gc
import sys
import tracemalloc
from collections import defaultdict
from typing import Dict, List

class MemoryLeakDetector:
    def __init__(self):
        self.snapshots = []
        self.object_counts = defaultdict(int)
        tracemalloc.start()
    
    def take_snapshot(self, label: str = ""):
        """æ‹æ‘„å†…å­˜å¿«ç…§"""
        snapshot = tracemalloc.take_snapshot()
        self.snapshots.append((label, snapshot))
        
        # ç»Ÿè®¡å¯¹è±¡æ•°é‡
        for obj_type in gc.get_objects():
            type_name = type(obj_type).__name__
            self.object_counts[type_name] += 1
    
    def compare_snapshots(self, start_index: int = 0, end_index: int = -1):
        """æ¯”è¾ƒå†…å­˜å¿«ç…§"""
        if len(self.snapshots) < 2:
            print("éœ€è¦è‡³å°‘ä¸¤ä¸ªå¿«ç…§è¿›è¡Œæ¯”è¾ƒ")
            return
        
        start_label, start_snapshot = self.snapshots[start_index]
        end_label, end_snapshot = self.snapshots[end_index]
        
        top_stats = end_snapshot.compare_to(start_snapshot, 'lineno')
        
        print(f"å†…å­˜å˜åŒ–å¯¹æ¯” ({start_label} -> {end_label}):")
        for stat in top_stats[:10]:
            print(stat)
    
    def find_memory_leaks(self) -> List[str]:
        """æŸ¥æ‰¾å¯èƒ½çš„å†…å­˜æ³„æ¼"""
        leaks = []
        
        # æ£€æŸ¥å¼•ç”¨è®¡æ•°å¼‚å¸¸é«˜çš„å¯¹è±¡
        for obj in gc.get_objects():
            ref_count = sys.getrefcount(obj)
            if ref_count > 100:  # é˜ˆå€¼å¯è°ƒæ•´
                leaks.append(f"é«˜å¼•ç”¨è®¡æ•°å¯¹è±¡: {type(obj).__name__} ({ref_count} å¼•ç”¨)")
        
        # æ£€æŸ¥å¾ªç¯å¼•ç”¨
        gc.collect()
        if gc.garbage:
            leaks.append(f"å‘ç° {len(gc.garbage)} ä¸ªæ— æ³•å›æ”¶çš„å¯¹è±¡")
        
        return leaks
    
    def get_largest_objects(self, limit: int = 10) -> List[str]:
        """è·å–å ç”¨å†…å­˜æœ€å¤§çš„å¯¹è±¡"""
        if not self.snapshots:
            return []
        
        _, latest_snapshot = self.snapshots[-1]
        top_stats = latest_snapshot.statistics('lineno')
        
        return [str(stat) for stat in top_stats[:limit]]

# ä½¿ç”¨ç¤ºä¾‹
detector = MemoryLeakDetector()

# åœ¨å…³é”®ç‚¹æ‹æ‘„å¿«ç…§
detector.take_snapshot("å¼€å§‹")
# ... è¿è¡Œä»£ç  ...
detector.take_snapshot("å¤„ç†å")

# åˆ†æç»“æœ
detector.compare_snapshots()
leaks = detector.find_memory_leaks()
if leaks:
    print("å¯èƒ½çš„å†…å­˜æ³„æ¼:")
    for leak in leaks:
        print(f"  - {leak}")
```

## æ—¥å¿—åˆ†æ

### æ—¥å¿—åˆ†æå·¥å…·

```python
# log_analyzer.py
import re
import json
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Tuple

class LogAnalyzer:
    def __init__(self, log_file_path: str):
        self.log_file_path = log_file_path
        self.error_patterns = {
            'timeout': r'timeout|timed out',
            'connection': r'connection.*error|failed to connect',
            'memory': r'out of memory|memory error',
            'api_error': r'api.*error|rate limit|authentication',
            'import_error': r'import.*error|module.*not found'
        }
    
    def analyze_errors(self, hours: int = 24) -> Dict[str, int]:
        """åˆ†æé”™è¯¯æ—¥å¿—"""
        error_counts = defaultdict(int)
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    # å°è¯•è§£æJSONæ ¼å¼æ—¥å¿—
                    log_entry = json.loads(line)
                    log_time = datetime.fromisoformat(log_entry.get('timestamp', ''))
                    
                    if log_time < cutoff_time:
                        continue
                    
                    level = log_entry.get('level', '').lower()
                    message = log_entry.get('message', '')
                    
                    if level in ['error', 'critical']:
                        # åŒ¹é…é”™è¯¯æ¨¡å¼
                        for error_type, pattern in self.error_patterns.items():
                            if re.search(pattern, message, re.IGNORECASE):
                                error_counts[error_type] += 1
                                break
                        else:
                            error_counts['other'] += 1
                
                except (json.JSONDecodeError, ValueError):
                    # å¤„ç†éJSONæ ¼å¼æ—¥å¿—
                    if 'ERROR' in line or 'CRITICAL' in line:
                        for error_type, pattern in self.error_patterns.items():
                            if re.search(pattern, line, re.IGNORECASE):
                                error_counts[error_type] += 1
                                break
        
        return dict(error_counts)
    
    def find_performance_issues(self) -> List[str]:
        """æŸ¥æ‰¾æ€§èƒ½é—®é¢˜"""
        issues = []
        slow_operations = []
        
        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                # æŸ¥æ‰¾æ‰§è¡Œæ—¶é—´è¿‡é•¿çš„æ“ä½œ
                duration_match = re.search(r'æ‰§è¡Œæ—¶é—´[ï¼š:]\s*(\d+\.?\d*)ç§’', line)
                if duration_match:
                    duration = float(duration_match.group(1))
                    if duration > 10:  # è¶…è¿‡10ç§’
                        slow_operations.append((duration, line.strip()))
        
        if slow_operations:
            slow_operations.sort(reverse=True)
            issues.append(f"å‘ç° {len(slow_operations)} ä¸ªæ…¢æ“ä½œ")
            for duration, log_line in slow_operations[:5]:
                issues.append(f"  - {duration:.2f}ç§’: {log_line[:100]}...")
        
        return issues
    
    def get_error_trends(self, days: int = 7) -> Dict[str, List[int]]:
        """è·å–é”™è¯¯è¶‹åŠ¿"""
        trends = defaultdict(lambda: [0] * days)
        
        for day in range(days):
            start_time = datetime.now() - timedelta(days=day+1)
            end_time = datetime.now() - timedelta(days=day)
            
            day_errors = self._count_errors_in_timerange(start_time, end_time)
            
            for error_type, count in day_errors.items():
                trends[error_type][days-1-day] = count
        
        return dict(trends)
    
    def _count_errors_in_timerange(self, start_time: datetime, end_time: datetime) -> Dict[str, int]:
        """ç»Ÿè®¡æ—¶é—´èŒƒå›´å†…çš„é”™è¯¯"""
        error_counts = defaultdict(int)
        
        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    log_entry = json.loads(line)
                    log_time = datetime.fromisoformat(log_entry.get('timestamp', ''))
                    
                    if start_time <= log_time < end_time:
                        level = log_entry.get('level', '').lower()
                        if level in ['error', 'critical']:
                            message = log_entry.get('message', '')
                            for error_type, pattern in self.error_patterns.items():
                                if re.search(pattern, message, re.IGNORECASE):
                                    error_counts[error_type] += 1
                                    break
                
                except (json.JSONDecodeError, ValueError):
                    continue
        
        return dict(error_counts)

# ä½¿ç”¨ç¤ºä¾‹
analyzer = LogAnalyzer('logs/agent_workflow.log')

# åˆ†ææœ€è¿‘24å°æ—¶çš„é”™è¯¯
errors = analyzer.analyze_errors(24)
print("é”™è¯¯ç»Ÿè®¡:", errors)

# æŸ¥æ‰¾æ€§èƒ½é—®é¢˜
performance_issues = analyzer.find_performance_issues()
if performance_issues:
    print("æ€§èƒ½é—®é¢˜:")
    for issue in performance_issues:
        print(f"  {issue}")

# è·å–é”™è¯¯è¶‹åŠ¿
trends = analyzer.get_error_trends(7)
print("é”™è¯¯è¶‹åŠ¿:", trends)
```

## è°ƒè¯•å·¥å…·

### äº¤äº’å¼è°ƒè¯•å™¨

```python
# interactive_debugger.py
import asyncio
import sys
import traceback
from typing import Any, Dict

class InteractiveDebugger:
    def __init__(self):
        self.context = {}
        self.history = []
    
    async def debug_session(self, initial_context: Dict[str, Any] = None):
        """å¯åŠ¨äº¤äº’å¼è°ƒè¯•ä¼šè¯"""
        if initial_context:
            self.context.update(initial_context)
        
        print("ğŸ› äº¤äº’å¼è°ƒè¯•å™¨å¯åŠ¨")
        print("è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        print("è¾“å…¥ 'exit' é€€å‡ºè°ƒè¯•å™¨")
        
        while True:
            try:
                command = input("debug> ").strip()
                
                if command == 'exit':
                    break
                elif command == 'help':
                    self._show_help()
                elif command == 'context':
                    self._show_context()
                elif command == 'history':
                    self._show_history()
                elif command.startswith('set '):
                    self._handle_set_command(command)
                elif command.startswith('get '):
                    self._handle_get_command(command)
                elif command.startswith('call '):
                    await self._handle_call_command(command)
                else:
                    # æ‰§è¡ŒPythonä»£ç 
                    await self._execute_code(command)
                
                self.history.append(command)
            
            except KeyboardInterrupt:
                print("\nä½¿ç”¨ 'exit' é€€å‡ºè°ƒè¯•å™¨")
            except Exception as e:
                print(f"é”™è¯¯: {e}")
                traceback.print_exc()
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
å¯ç”¨å‘½ä»¤:
  help          - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  context       - æ˜¾ç¤ºå½“å‰ä¸Šä¸‹æ–‡å˜é‡
  history       - æ˜¾ç¤ºå‘½ä»¤å†å²
  set <var> <value> - è®¾ç½®å˜é‡
  get <var>     - è·å–å˜é‡å€¼
  call <func>   - è°ƒç”¨å‡½æ•°
  exit          - é€€å‡ºè°ƒè¯•å™¨
  
ä¹Ÿå¯ä»¥ç›´æ¥è¾“å…¥Pythonä»£ç æ‰§è¡Œ
        """
        print(help_text)
    
    def _show_context(self):
        """æ˜¾ç¤ºä¸Šä¸‹æ–‡"""
        print("å½“å‰ä¸Šä¸‹æ–‡å˜é‡:")
        for key, value in self.context.items():
            print(f"  {key}: {type(value).__name__} = {repr(value)[:100]}")
    
    def _show_history(self):
        """æ˜¾ç¤ºå†å²å‘½ä»¤"""
        print("å‘½ä»¤å†å²:")
        for i, cmd in enumerate(self.history[-10:], 1):
            print(f"  {i}: {cmd}")
    
    def _handle_set_command(self, command: str):
        """å¤„ç†setå‘½ä»¤"""
        parts = command.split(' ', 2)
        if len(parts) >= 3:
            var_name = parts[1]
            var_value = ' '.join(parts[2:])
            try:
                # å°è¯•eval
                self.context[var_name] = eval(var_value, self.context)
                print(f"è®¾ç½® {var_name} = {self.context[var_name]}")
            except:
                # ä½œä¸ºå­—ç¬¦ä¸²å¤„ç†
                self.context[var_name] = var_value
                print(f"è®¾ç½® {var_name} = '{var_value}'")
        else:
            print("ç”¨æ³•: set <å˜é‡å> <å€¼>")
    
    def _handle_get_command(self, command: str):
        """å¤„ç†getå‘½ä»¤"""
        parts = command.split(' ', 1)
        if len(parts) >= 2:
            var_name = parts[1]
            if var_name in self.context:
                print(f"{var_name} = {repr(self.context[var_name])}")
            else:
                print(f"å˜é‡ '{var_name}' ä¸å­˜åœ¨")
        else:
            print("ç”¨æ³•: get <å˜é‡å>")
    
    async def _handle_call_command(self, command: str):
        """å¤„ç†callå‘½ä»¤"""
        parts = command.split(' ', 1)
        if len(parts) >= 2:
            func_call = parts[1]
            try:
                result = eval(func_call, self.context)
                if asyncio.iscoroutine(result):
                    result = await result
                print(f"ç»“æœ: {repr(result)}")
                self.context['_last_result'] = result
            except Exception as e:
                print(f"è°ƒç”¨å¤±è´¥: {e}")
        else:
            print("ç”¨æ³•: call <å‡½æ•°è°ƒç”¨>")
    
    async def _execute_code(self, code: str):
        """æ‰§è¡ŒPythonä»£ç """
        try:
            # å°è¯•ä½œä¸ºè¡¨è¾¾å¼æ‰§è¡Œ
            result = eval(code, self.context)
            if asyncio.iscoroutine(result):
                result = await result
            if result is not None:
                print(repr(result))
                self.context['_'] = result
        except SyntaxError:
            # ä½œä¸ºè¯­å¥æ‰§è¡Œ
            try:
                exec(code, self.context)
            except Exception as e:
                print(f"æ‰§è¡Œé”™è¯¯: {e}")
        except Exception as e:
            print(f"æ‰§è¡Œé”™è¯¯: {e}")

# ä½¿ç”¨ç¤ºä¾‹
async def debug_agent_issue():
    """è°ƒè¯•ä»£ç†é—®é¢˜"""
    from src.core.config.config_manager import ConfigManager
    from src.agents.factory.agent_factory import AgentFactory
    
    # å‡†å¤‡è°ƒè¯•ä¸Šä¸‹æ–‡
    context = {
        'config_manager': ConfigManager(),
        'agent_factory': AgentFactory(),
        'asyncio': asyncio
    }
    
    debugger = InteractiveDebugger()
    await debugger.debug_session(context)

if __name__ == "__main__":
    asyncio.run(debug_agent_issue())
```

## å¸¸è§é”™è¯¯ä»£ç 

### é”™è¯¯ä»£ç å¯¹ç…§è¡¨

| é”™è¯¯ä»£ç  | æè¿° | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|----------|
| AGW-001 | é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ | æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ | æ£€æŸ¥é…ç½®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼ |
| AGW-002 | APIå¯†é’¥æ— æ•ˆ | å¯†é’¥é”™è¯¯æˆ–è¿‡æœŸ | æ›´æ–°APIå¯†é’¥ |
| AGW-003 | æ¨¡å—å¯¼å…¥å¤±è´¥ | Pythonè·¯å¾„é…ç½®é—®é¢˜ | æ£€æŸ¥PYTHONPATHè®¾ç½® |
| AGW-004 | æ•°æ®åº“è¿æ¥å¤±è´¥ | è¿æ¥å­—ç¬¦ä¸²é”™è¯¯æˆ–æœåŠ¡ä¸å¯ç”¨ | æ£€æŸ¥æ•°æ®åº“é…ç½®å’ŒæœåŠ¡çŠ¶æ€ |
| AGW-005 | ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ | ä»»åŠ¡å¤æ‚åº¦è¿‡é«˜æˆ–èµ„æºä¸è¶³ | å¢åŠ è¶…æ—¶æ—¶é—´æˆ–ä¼˜åŒ–ä»»åŠ¡ |
| AGW-006 | å†…å­˜ä¸è¶³ | å†…å­˜æ³„æ¼æˆ–æ•°æ®é‡è¿‡å¤§ | æ£€æŸ¥å†…å­˜ä½¿ç”¨å’Œä¼˜åŒ–ä»£ç  |
| AGW-007 | ç½‘ç»œè¿æ¥é”™è¯¯ | ç½‘ç»œé—®é¢˜æˆ–ä»£ç†é…ç½® | æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½® |
| AGW-008 | æƒé™ä¸è¶³ | æ–‡ä»¶æˆ–ç›®å½•æƒé™é—®é¢˜ | æ£€æŸ¥æ–‡ä»¶æƒé™è®¾ç½® |
| AGW-009 | ä¾èµ–ç‰ˆæœ¬å†²çª | åŒ…ç‰ˆæœ¬ä¸å…¼å®¹ | æ›´æ–°æˆ–é™çº§ç›¸å…³åŒ… |
| AGW-010 | å¼‚æ­¥æ“ä½œé”™è¯¯ | äº‹ä»¶å¾ªç¯é—®é¢˜ | æ£€æŸ¥å¼‚æ­¥ä»£ç å®ç° |

### è‡ªåŠ¨é”™è¯¯è¯Šæ–­

```python
# auto_diagnosis.py
import sys
import traceback
from typing import Dict, List, Tuple

class AutoDiagnostic:
    def __init__(self):
        self.error_solutions = {
            'ModuleNotFoundError': self._diagnose_import_error,
            'FileNotFoundError': self._diagnose_file_error,
            'ConnectionError': self._diagnose_connection_error,
            'TimeoutError': self._diagnose_timeout_error,
            'MemoryError': self._diagnose_memory_error,
            'PermissionError': self._diagnose_permission_error,
        }
    
    def diagnose_exception(self, exc: Exception) -> List[str]:
        """è¯Šæ–­å¼‚å¸¸å¹¶æä¾›è§£å†³å»ºè®®"""
        exc_type = type(exc).__name__
        suggestions = []
        
        # é€šç”¨å»ºè®®
        suggestions.append(f"é”™è¯¯ç±»å‹: {exc_type}")
        suggestions.append(f"é”™è¯¯ä¿¡æ¯: {str(exc)}")
        
        # ç‰¹å®šè¯Šæ–­
        if exc_type in self.error_solutions:
            specific_suggestions = self.error_solutions[exc_type](exc)
            suggestions.extend(specific_suggestions)
        
        # å †æ ˆè·Ÿè¸ªåˆ†æ
        stack_suggestions = self._analyze_stack_trace(exc)
        suggestions.extend(stack_suggestions)
        
        return suggestions
    
    def _diagnose_import_error(self, exc: ModuleNotFoundError) -> List[str]:
        """è¯Šæ–­å¯¼å…¥é”™è¯¯"""
        module_name = str(exc).split("'")[1] if "'" in str(exc) else "unknown"
        
        suggestions = [
            "å¯¼å…¥é”™è¯¯è¯Šæ–­:",
            f"  1. æ£€æŸ¥æ¨¡å— '{module_name}' æ˜¯å¦å·²å®‰è£…: pip list | grep {module_name}",
            f"  2. å®‰è£…ç¼ºå¤±æ¨¡å—: pip install {module_name}",
            "  3. æ£€æŸ¥PYTHONPATHè®¾ç½®: echo $PYTHONPATH",
            "  4. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒæ˜¯å¦æ¿€æ´»",
            "  5. æ£€æŸ¥é¡¹ç›®ç»“æ„å’Œ__init__.pyæ–‡ä»¶"
        ]
        
        if 'src.' in module_name:
            suggestions.extend([
                "  6. é¡¹ç›®æ¨¡å—å¯¼å…¥é—®é¢˜:",
                "     - ç¡®ä¿srcç›®å½•åœ¨Pythonè·¯å¾„ä¸­",
                "     - è¿è¡Œ: export PYTHONPATH=$PYTHONPATH:$(pwd)/src",
                "     - æˆ–å®‰è£…ä¸ºå¯ç¼–è¾‘åŒ…: pip install -e ."
            ])
        
        return suggestions
    
    def _diagnose_file_error(self, exc: FileNotFoundError) -> List[str]:
        """è¯Šæ–­æ–‡ä»¶é”™è¯¯"""
        filename = exc.filename or "unknown"
        
        return [
            "æ–‡ä»¶é”™è¯¯è¯Šæ–­:",
            f"  1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨: ls -la {filename}",
            f"  2. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®",
            f"  3. æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•: pwd",
            f"  4. æ£€æŸ¥æ–‡ä»¶æƒé™: ls -la $(dirname {filename})",
            f"  5. å¦‚æœæ˜¯é…ç½®æ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºé»˜è®¤é…ç½®"
        ]
    
    def _diagnose_connection_error(self, exc: Exception) -> List[str]:
        """è¯Šæ–­è¿æ¥é”™è¯¯"""
        return [
            "è¿æ¥é”™è¯¯è¯Šæ–­:",
            "  1. æ£€æŸ¥ç½‘ç»œè¿æ¥: ping google.com",
            "  2. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®",
            "  3. æ£€æŸ¥ä»£ç†é…ç½®: echo $HTTP_PROXY",
            "  4. æ£€æŸ¥APIç«¯ç‚¹æ˜¯å¦å¯è®¿é—®",
            "  5. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ",
            "  6. æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ"
        ]
    
    def _diagnose_timeout_error(self, exc: Exception) -> List[str]:
        """è¯Šæ–­è¶…æ—¶é”™è¯¯"""
        return [
            "è¶…æ—¶é”™è¯¯è¯Šæ–­:",
            "  1. å¢åŠ è¶…æ—¶æ—¶é—´è®¾ç½®",
            "  2. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ: ping target_host",
            "  3. æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½: top",
            "  4. ä¼˜åŒ–ä»£ç æ€§èƒ½",
            "  5. è€ƒè™‘ä½¿ç”¨å¼‚æ­¥å¤„ç†",
            "  6. æ£€æŸ¥æ˜¯å¦æœ‰æ­»é”"
        ]
    
    def _diagnose_memory_error(self, exc: MemoryError) -> List[str]:
        """è¯Šæ–­å†…å­˜é”™è¯¯"""
        return [
            "å†…å­˜é”™è¯¯è¯Šæ–­:",
            "  1. æ£€æŸ¥ç³»ç»Ÿå†…å­˜ä½¿ç”¨: free -h",
            "  2. æ£€æŸ¥è¿›ç¨‹å†…å­˜ä½¿ç”¨: ps aux | grep python",
            "  3. æŸ¥æ‰¾å†…å­˜æ³„æ¼",
            "  4. ä¼˜åŒ–æ•°æ®ç»“æ„ä½¿ç”¨",
            "  5. ä½¿ç”¨ç”Ÿæˆå™¨ä»£æ›¿åˆ—è¡¨",
            "  6. åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡",
            "  7. è€ƒè™‘å¢åŠ ç³»ç»Ÿå†…å­˜"
        ]
    
    def _diagnose_permission_error(self, exc: PermissionError) -> List[str]:
        """è¯Šæ–­æƒé™é”™è¯¯"""
        return [
            "æƒé™é”™è¯¯è¯Šæ–­:",
            "  1. æ£€æŸ¥æ–‡ä»¶æƒé™: ls -la target_file",
            "  2. æ£€æŸ¥ç›®å½•æƒé™: ls -ld target_directory",
            "  3. æ£€æŸ¥ç”¨æˆ·æƒé™: whoami",
            "  4. ä¿®æ”¹æ–‡ä»¶æƒé™: chmod 644 target_file",
            "  5. ä¿®æ”¹ç›®å½•æƒé™: chmod 755 target_directory",
            "  6. æ£€æŸ¥SELinuxè®¾ç½® (Linux)"
        ]
    
    def _analyze_stack_trace(self, exc: Exception) -> List[str]:
        """åˆ†æå †æ ˆè·Ÿè¸ª"""
        suggestions = []
        tb = traceback.extract_tb(exc.__traceback__)
        
        if tb:
            last_frame = tb[-1]
            suggestions.extend([
                "å †æ ˆè·Ÿè¸ªåˆ†æ:",
                f"  é”™è¯¯å‘ç”Ÿåœ¨: {last_frame.filename}:{last_frame.lineno}",
                f"  å‡½æ•°: {last_frame.name}",
                f"  ä»£ç : {last_frame.line}"
            ])
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®ä»£ç 
            if 'src/' in last_frame.filename or 'AgentWorker/' in last_frame.filename:
                suggestions.append("  è¿™æ˜¯é¡¹ç›®ä»£ç ä¸­çš„é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³é€»è¾‘")
            else:
                suggestions.append("  è¿™æ˜¯ç¬¬ä¸‰æ–¹åº“ä¸­çš„é”™è¯¯ï¼Œå¯èƒ½æ˜¯ä½¿ç”¨æ–¹å¼ä¸å½“")
        
        return suggestions

# å…¨å±€å¼‚å¸¸å¤„ç†å™¨
def setup_global_exception_handler():
    """è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    diagnostic = AutoDiagnostic()
    
    def handle_exception(exc_type, exc_value, exc_traceback):
        if issubclass(exc_type, KeyboardInterrupt):
            sys.__excepthook__(exc_type, exc_value, exc_traceback)
            return
        
        print("\n" + "="*50)
        print("ğŸš¨ å‘ç”Ÿæœªå¤„ç†çš„å¼‚å¸¸")
        print("="*50)
        
        # æ˜¾ç¤ºåŸå§‹é”™è¯¯
        traceback.print_exception(exc_type, exc_value, exc_traceback)
        
        print("\n" + "-"*50)
        print("ğŸ”§ è‡ªåŠ¨è¯Šæ–­å»ºè®®")
        print("-"*50)
        
        # æ˜¾ç¤ºè¯Šæ–­å»ºè®®
        suggestions = diagnostic.diagnose_exception(exc_value)
        for suggestion in suggestions:
            print(suggestion)
        
        print("\n" + "="*50)
    
    sys.excepthook = handle_exception

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    setup_global_exception_handler()
    
    # æµ‹è¯•å„ç§é”™è¯¯
    try:
        import non_existent_module
    except Exception as e:
        diagnostic = AutoDiagnostic()
        suggestions = diagnostic.diagnose_exception(e)
        for suggestion in suggestions:
            print(suggestion)
```

---

é€šè¿‡ä½¿ç”¨æœ¬æ•…éšœæ’é™¤æŒ‡å—ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿè¯Šæ–­å’Œè§£å†³AI Agents Workflowæ¡†æ¶ä¸­é‡åˆ°çš„å„ç§é—®é¢˜ã€‚å»ºè®®å°†å¸¸ç”¨çš„è¯Šæ–­è„šæœ¬ä¿å­˜ä¸ºé¡¹ç›®å·¥å…·ï¼Œä»¥ä¾¿åœ¨é‡åˆ°é—®é¢˜æ—¶å¿«é€Ÿä½¿ç”¨ã€‚